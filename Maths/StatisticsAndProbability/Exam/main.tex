\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{hyperref}
\usepackage{datetime}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{tikz}
\graphicspath{ {./Images/} }

% For slope Fields
\usepackage{pgfplots}
\usetikzlibrary{calc}
\usetikzlibrary{shapes.geometric}
\pgfplotsset{compat=1.8}

\author{Григорий Матюхин}
\date{\today}
\title{
	Теория вероятностей и математическая статистика \\
	\large Подготовка к экзамену.
}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

\section{Тема 1. Случайный эксперимент и пространство элементарных исходов}

\subsection{Случайный эксперимент}

\subsection{Условия проведения эксперимента}

\subsection{Элементарный исход эксперимента}
<<Неделимый>> исход эксперимента. $\omega$.

\subsection{Пространство элементарных исходов}
Все возможные исходы эксперимента. $\Omega = \{\omega_1, \omega_2, ..., \omega_n\}$.

\subsection{Наблюдаемые события}

\subsection{Модель эксперимента}
Совокупность объектов:
\begin{itemize}
	\item $\langle \mathcal{K}, \Omega, 2^{|\Omega|}\rangle$,
	      если все элементарные события $\omega \in \Omega$ являются наблюдаемыми.
	\item $\langle \mathcal{K}, \Omega, \mathit{z}, 2^{|\mathit{z}|}\rangle$,
	      если наблюдаемыми являются лишь события, образующие разбиение $\mathit{z}(\Omega)$.
\end{itemize}
где $\mathcal{K}$ --- комплекс основных условий и действий, характерихующих эксперимент $G$ и позволяющих его многократно повторять.

\subsection{Событие, достоверное и невозможное}
Событие ($A, B, C_1, ... $) --- произвольный набор элементарных исходов,
или, другими словами, произвольное подмножество множества элементарных исходов. \\
Если $A = \Omega$, то $A$ --- достоверное событие. \\
$\varnothing$ --- невозможное событие, не происходит никогда, не содержит ни одного элементарного исхода.

\subsection{Операции над множествами и событиями}
\begin{itemize}
	\item Пересечение \\
	      \[C = A \cap B\]
	      или
	      \[C = A \cdot B\]
	\item Объединение \\
	      \[C = A \cup B\]
	      или
	      \[C = A + B\]
	\item Разность \\
	      \[C = A \setminus B\]
	\item Симметрическая разность \\
	      \[C = A \triangle B = (A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\]
	\item Дополнение \\
	      \[\overline{A} = \Omega \setminus A\]
	\item Формулы де Моргана \\
	      \[A \cap B = \overline{\overline{A} \cup \overline{B}}\]
	      \[A \cup B = \overline{\overline{A} \cap \overline{B}}\]
	\item Включение \\
	      \[A \subset B \Rightarrow\]
	      \[A \cup B = B\]
	      \[A \setminus B = \varnothing\]
	      \[A \triangle B = B \setminus A\]
\end{itemize}

\section{Тема 2. Сигма-алгебра событий и вероятностное пространство}
Если $\Omega$ более чем счетно, то мы уже не сможем построить логически непротиворечивую теорию,
называя событием произвольное подмножество $\Omega$.
Причина этого заключается в существовании так называемых неизмеримых множеств,
что в свою очередь кроется в топологической структуре классических рассматриваемых пространств
(прямой, плоскости, трехмерного пространства и т.д.).
Поэтому приходится отказаться от естественного желания назвать событием любое
подмножество элементарных исходов $\Omega$
и выделить среди всех подмножеств некоторый класс подмножеств $\mathcal{B}$.
Именно только подмножества из выделенного класса $\mathcal{B}$ и будут называться событиями.

\subsection{Алгебра конечных подмножеств и алгебра событий}
Алгебра событий $\mathcal{A}$ --- непустая схема подмножеств $\Omega$, удовлетворяющая следующим аксиомам:
\begin{itemize}
	\item[A1:] $A \in \mathcal{A} \Rightarrow \overline{A} \in \mathcal{A}$
	\item[A2:] $A,B \in \mathcal{A} \Rightarrow A \cup B \in \mathcal{A}$
\end{itemize}

Свойства:
\begin{enumerate}
	\item $\mathcal{A}$ --- замкнутая система подмножеств $\Omega$ относительно конечного числа теоретико-множественных операций
	\item $A,B \in \mathcal{A} \Rightarrow A \cap B \in \mathcal{A}, A \setminus B \in \mathcal{A}, A \triangle B \in \mathcal{A}$
	\item $\Omega \in \mathcal{A}, \varnothing \in \mathcal{A}$
\end{enumerate}

\subsection{Сигма-алгебра счетных подмножеств и сигма-алгебра событий}
Для пространства элементарных исходов, не являющимся конечным, не достаточно ограничиться алгебрами.
Таким образом $\sigma$-алгебра событий $\mathcal{B}$ --- непустой класс подмножеств $\Omega$, удовлетворяющая следующим аксиомам:
\begin{itemize}
	\item[A1:] $A \in \mathcal{B} \Rightarrow \overline{A} \in \mathcal{B}$
	\item[A2$'$:] $A_i \in \mathcal{B}, i = 1,2,... \Rightarrow \bigcup^{\infty}_{i = 1}A_i \in \mathcal{B}$
\end{itemize}

Свойства:
\begin{enumerate}
	\item $\Omega \in \mathcal{B}, \varnothing \in \mathcal{B}$
	\item $\bigcap^{\infty}_{i=1}A_i \in \mathcal{B}$
	\item Любая $\sigma$-алгебра событий является одновременно и алгеброй событий
	\item Если пространство элементарных исходов $\Omega$ конечно,
	      то любая алгебра событий является $\sigma$-алгеброй событий.
	\item $\mathcal{B}$ --- замкнутая система подмножеств $\Omega$ относительно конечного числа теоретико-множественных операций
\end{enumerate}

\subsection{Сигма-алгебра борелевских подмножеств и борелевская сигма-алгебра событий}
Пусть $\Omega = (-\infty, \infty)$. Минимальная $\sigma$-алгебра,
которой принадлежат всевозможные интервалы $[a, b], [a, b), (a, b], (a, b)$ так,
что $a < b, a \in \Omega, b \in \Omega$,
носит название \textit{борелевской $\sigma$-алгебры} и является тем объектом,
на котором без всяких логических противоречийможно построить математически строгую теорию. \\
Все сказанное относительно прямой в полной мере относится и к пространствам исходов,
представляющим собой плоскость, трехмерное пространство и пространства более высоких размерностей,
а также их невырожденные части (отрезки, многоугольники, круги, шары и т.д.).
В теории вероятностей такие пространства элементарных исходов называются непрерывными.

\subsection{Измеримое пространнство, мера множества и ее свойства}
\subsection{Сигма-аддитивная мера множества}
\subsection{Вероятностная мера (вероятность)}
\subsection{Пространство с мерой}
\subsection{Вероятностное пространство}
Вероятностной моделью эксперимента $G$ с конечным множеством $\Omega$
равновозможных исходов служит система объектов
\[\langle \Omega; P(\omega) = \frac{1}{|\Omega|}, \omega \in \Omega \rangle\]
называется \textbf{вероятностным пространством}.

\section{Тема 3. Определение вероятности и ее свойства}

\subsection{Классическая вероятность}
Если $\Omega = \{\omega_1, ... \omega_n\}, 1 \leq n < \infty$,
и все элементарные события наблюдаемы и равнозначны,
то вероятность элементарного исхода:
\[P(\omega_i) = \frac{1}{n}, i = 1, ..., n\]
В классической схеме вероятность любого события
$A = \{\omega_{i_1}, ..., \omega_{i_m}\} \subset \Omega$ определяется
как отношение числа $m$ благоприятных для события $A$ элементарных исходов
к общему числу элементарных исходов $n$. \\
\[P(A) = \frac{|A|}{|\Omega|} = \frac{m}{n}, 0 \leq m < n\]

\subsection{Свойства класической вероятности}

\subsection{Геометрическая вероятность}
% Todo: expand reasoning here
Пусть $\Omega$ --- некоторая область, имеющая меру $\mu(\Omega)$ (длину, площадь, объем и т.д.), такую,
что $0 < \mu(\Omega) < \infty$.
Скажем,что точка равномерным образом попадает в $\Omega$ (реализуется принцип геометрической вероятности),
если вероятность $P(A)$ попадания ее в каждую область $A$, являющуюся подобластью $\Omega$,
пропорциональна мере этой области $\mu(A)$. \\
\[P(A) = \frac{\mu(A)}{\mu(\Omega)}\]

\subsection{Статистическое определение вероятности}
% Todo: rewrite
При достаточно больших повторениях $N_1, N_2, ...$ экспериментов $G_1, G_2, ...$ относительные
частоты события $A$ называются статистически устойчивым, и колеблются вокург некоторого значения $P(A)$.
$P(A)$ называется вероятностью события $A$, а оценкой $P(A)$ служит статистическая вероятность
\[\widehat{P_N}(A) = \frac{\sum^m_{i=1}N_i(A)}{\sum^m_{i=1}N_i}\]

\subsection{Пример статистического расчета вероятности}

\subsection{Модель случайного эксперимента в виде вероятностного пространства}

\subsection{Аксиоматическое определение вероятности. Система аксиом А.Н. Колмогорова}
\begin{itemize}
	\item[P1.\label{prob_ax:P1}] $P(A) \geq 0$ --- аксиома неотрицательности;
	\item[P2.\label{prob_ax:P2}] $P(\Omega) = 1$ --- аксиома нормированности;
	\item[P3.\label{prob_ax:P3}] $P(A + B) = P(A) + P(B)$ --- аксиома сложения, если
		$A, B \in \mathcal{B}, A \cup B = \varnothing$;
	\item[P3$'$.] $P(A_1 + ... + A_n + ...) = P(A_1) + ... + P(A_n) + ...$ ---
		расширенная аксиома сложения в случае произвольного (не обязательно конечного)
		пространства элементарных исходов для счетного числа попарно несовместных событий.
\end{itemize}

\subsection{Свойства вероятности}
\begin{enumerate} % Todo: fill in the reasoning
	\item $P(\overline{A}) = 1 - P(A) \because$ \\
	      $\Omega = A + \overline{A} \Rightarrow P(\Omega) = P(A) + P(\overline{A})$ \ref{prob_ax:P3}
	\item $P(\varnothing) = 0 \because$ \\
	      $A = A + \varnothing$ \ref{prob_ax:P3}
	\item $P(A) \leq P(B)$ если $A \subset B \because$ \\
	      $A \subset B \Rightarrow B = A + (B \setminus A) \Rightarrow P(B) = P(A) + P(B \setminus A)$
	\item $0 \leq P(A) \leq 1 \because$ \\
	      $A \subset \Omega$
	\item $P(A \cup B) = P(A) + P(B) - P(AB) \because$ \\
	      $A \cup B = A + (B \setminus A), B = (B \setminus A) + AB \Rightarrow \\P(A \cup B) = P(A) + P(B \setminus A), P(B \setminus A) = P(B) - P(AB)$
	\item $P(A_1 \cup ... \cup A_n) = P(A_1) + ... + P(A_n) - P(A_1A_2) - P(A_1A_3) - ... \\
		      ... - P(A_{n-1}A_n) + P(A_1A_2A_3) + ... + (-1)^{n+1}P(A_1A_2...A_n) \because$ \\
	      $P(A \cup B \cup C ) = P(A) + P(B \cup C) - P(A(B \cup C)) = ...$
	\item $P(A_1 + ... + A_n) = P(A_1) + ... + P(A_n)$
\end{enumerate}

\section{Тема 4. Условная вероятность и независимость событий}

\subsection{Условная вероятность}
Условную вероятность $P(B|A)$ события $B$ при условии события $A$ в рамках классической схемы
естественно определить как отношение числа исходов $m_{AB}$,
благоприятных для совместного осуществления событий $A$ и $B$,
к числу исходов $m_A$, благоприятных для события $A$, т. е.
\[P(B|A) = \frac{m_{AB}}{m_A} = \frac{\frac{m_{AB}}{n}}{\frac{m_A}{n}} = \frac{P(AB)}{P(A)}, n = |\Omega|\]
Условная вероятность обладает всеми свойствами безусловной вероятности. Так,
\begin{gather*}
	P(\Omega|A) = 1, \\
	P(\varnothing|A) = 0, \\
	P(C+B|A) = P(C|A) + P(B|A)
\end{gather*}
Также
\[P(\overline{B}|A) = 1 - P(B|A)\]
вытекает из
\[1 = P(\Omega|A) = P(B + \overline{B}|A) = P(B|A) + P(\overline{B}|A)\]

\subsection{Формула умножения вероятностей}
\[P(A_1A_2...A_n) = P(A_1)P(A_2|A_1)P(A_3|A_1A_2)...P(A_n|A_1A_2...A_{n-1})\]

Получение
\begin{gather*}
	P(A_n|A_1A_2...A_{n-1}) = \frac{P(A_1A_2...A_n)}{P(A_1A_2...A_{n-1})} \\
	P(A_1A_2...A_n) = P(A_n|A_1A_2...A_{n-1}) \times P(A_1A_2...A_{n-1})
\end{gather*}
аналогично
\begin{gather*}
	P(A_1A_2...A_{n-1}) = P(A_n|A_1A_2...A_{n-2}) \times P(A_1A_2...A_{n-2}) \\
	P(A_1A_2...A_{n-2}) = P(A_n|A_1A_2...A_{n-3}) \times P(A_1A_2...A_{n-3}) \\
	\vdots \\
	P(A_1A_2) = P(A_2|A_1) \times P(A_1)
\end{gather*}
Подставляем все в одну формулу.

\subsection{Независимость событий}
События $A$ и $B$ называются независимыми,
если условная вероятность события $B$ при условии $A$
совпадает с безусловной вероятностью события $B$, т.е.
\[P(B|A) = P(B)\]
Понятие независимости симметрично относительно перестановки событий $A$ и $B$,
т. е. если событие $B$ не зависит от события $A$,
то событие $A$ также не зависит от события $B$.
Для этого подставим вместо условной вероятности $P(B|A)$ ее значение $P(B|A) = P(AB)/P(A)$.
Тогда независимость событий $A$ и $B$ эквивалентна выполнению равенства
\[P(AB) = P(A)P(B)\]
Назовем события $A$, $B$ и $C$ независимыми (в совокупности), если
$P(AB) = P(A)P(B), P(AC) = P(A)P(C), P(BC) = P(B)P(C), P(ABC) = P(A)P(B)P(C)$

\subsection{Последовательное и параллельное соединение элементов в структурных схемах наадежности}
\begin{itemize}
	\item Последовательное соединеие: \\
	      Операция: $\cup$ \\
	      Формула: $P(A) = 1 - [1 - P(A_1)]...[1 - P(A_n)]$ (это формула де Моргана)
	\item Параллельное соединеие: \\
	      Операция: $\cap$ \\
	      Формула: $P(A) = P(A_1)...P(A_n)$
\end{itemize}

\subsection{<<Обобщенное>> соединение элементов в структурных схемах надежности}
\subsection{Задача приближенного расчета вероятности блокировки в проводной сети (метод просеянной нагрузки)}
\subsection{Формула полной вероятности}
Пусть события $H_i, i=\overline{1, n}$ --- гипотезы, так, что $H_iH_j = \varnothing$ при $i \neq j$ и $H_1 + ... + H_n = \Omega$. Пусть есть событие $A$ и даны $P(H_1), ..., P(H_n), P(A|H_1), ..., P(A|H_n)$. \\
Необходимо определить $P(A)$. \\
\begin{gather*}
	A = A\Omega = A(H_1 + ... + H_n) = AH_1 + ... + AH_n \\
	P(A) = P(AH_1) + ... + P(AH_n) \\
	P(AH_1) = P(H_1)P(A|H_1), ..., P(AH_n) = P(H_n)P(A|H_n) \\
\end{gather*}
Тогда \textbf{формула полной вероятности}
\begin{equation*}
	P(A) = P(H_1)P(A|H_1) + ... + P(H_n)P(A|H_n)
\end{equation*}

\subsection{Формула Байеса}
Во многих приложениях теории вероятностей встречается следующая задача.
Пусть до опыта имеются гипотезы $H_1, ..., H_n$.
После опытастановится известной информация о его результатах, но не полная.
А именно, результаты наблюдений показывают, не какой конкретно элементарный исход $\omega$
из пространства элементарных исходов $\Omega$ произошел, а что наступило некоторое событие $A$.
Считая, что до опыта были известны (априорные) вероятности гипотез $P(H_1), ..., P(H_n)$
и условные вероятности $P(A|H_1), ..., P(A|H_n)$,
необходимо определить (апостериорные) вероятности гипотез $P(H_1|A), ..., P(H_n|A)$.
\[P(H_i|A) = \frac{P(H_i)P(A|H_i)}{P(A)}\]
Т.к.
\begin{gather*}
	P(H_i|A) = \frac{P(AH_i)}{P(A)} \\
	P(AH_i) = P(H_i)P(A|H_i) \\
	P(H_i|A) = \frac{P(H_i)P(A|H_i)}{P(A)}
\end{gather*}

\section{Тема 5. Схема Бернулли и предельные теоремы}
\subsection{Схема Бернулли}
Опыт состоит в $n$-кратном повторении одинаковых испытаний,
в каждом из которых может с вероятностью $p$ наступить некоторое событие
(будемговорить в этом случае, что произошел «успех»)
или с вероятностью $q = 1 - p$ не наступить (произошла «неудача»).
Результат каждого опыта можно записать в виде последовательности УНН...У, состоящей из $n$ букв У и Н,
причем буква У (или Н) на $i$-м месте означает, что в $i$-м испытании произошел успех(или неудача).
Пространство элементарных исходов $\Omega$ состоит из $2^n$ исходов,
каждый из которых отождествляется с определенной последовательностью УНН...У
($\sigma$-алгебра событий $\mathcal{B}$ включает $2^{2^n}$ событий!).
Заметим теперь, что в независимости испытаний мы обязаны сопоставить каждому элементарному исходу
$\omega = ...$ вероятность $P(\omega) = P(...) = pqq...p$,
причем буква $p$ (или $q$) в произведении повторяется столько раз,
сколько раз произошел успех (или неудача).


\subsection{Формула Бернулли}
Событие $A_m$ --- в $n$ испытаниях произошло ровно $m$ успехов --- состоит из тех элементарных исходов,
в которых буква У по-появляется ровно $m$ раз.
Для того чтобы подсчитать число таких исходов, заметим,
что оно совпадает с числом способов, которыми можно расставить $m$ букв У на $n$ местах.
\[P_n(m) = C^m_np^mq^{n - m}, m = 0, 1, 2, ..., n\]

\subsection{Локальная предельная теорема Пуассона и формула Пуассона}
Пусть число испытаний $n$ в схеме Бернулли велико,
а вероятность успеха $p$ в одном испытании мала,
причем мало также произведение $\lambda = np$.
Тогда $P_n(m)$ определяется по приближенной формуле (формула Пуассона)
\[P_n(m) \approx \frac{\lambda^m}{m!}e^{-\lambda}\]

Доказательство:
Запишем ф. Бернулли
\begin{gather*}
	P_n(m) = C^m_np^m(1-p)^{n-m} = \frac{n(n-1)...(n-m+1)}{m!}p^m(1-p)^{n-m} = \\
	= \frac{p^m}{m!}n(n-1)...(n-m+1)(1-p)^{n-m} = \\
	= \frac{n^mp^m}{m!}\left(1 - \frac{1}{n}\right)...\left(1-\frac{m+1}{n}\right)(1-p)^n(1-p)^{-m} = \\
	= \frac{n^mp^m}{m!}\left(1 - \frac{1}{n}\right)...\left(1-\frac{m+1}{n}\right)\left(1-\frac{np}{n}\right)^n \left(1- \frac{np}{n}\right)^{-m}
\end{gather*}
Или, с учетом $\lambda = np$
\[P_n(m) = \frac{\lambda^m}{m!}\left(1 - \frac{1}{n}\right)...\left(1-\frac{m+1}{n}\right)\left(1-\frac{\lambda}{n}\right)^n\left(1- \frac{\lambda}{n}\right)^{-m}\]
При больших $n$ $(1-\lambda / n)^n \approx e^{-\lambda}$,
$(1 - 1 / n) \approx 1, (1 - 2 / n) \approx 1, ... \\ ... (1 - (m+1) / n) \approx 1$,
а $(1 - \lambda / n)^{-m} \approx 1$ \\
Поэтому
\[P_n(m) = \frac{\lambda^m}{m!}e^{-\lambda}\]

\subsection{Локальная предельная теорема Муавра-Лапласа и локальная формула Муавра-Лапласа}
Если в схеме Бернулли число испытаний $n$ велико,
то для всех $m$ справедлива приближенная формула (локальная формула Муавра-Лапласа)
\begin{gather*}
	\sqrt{npq}P_n(m) \approx \varphi(x), \\
	x = \frac{m-np}{\sqrt{npq}}, \varphi(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}
\end{gather*}

\subsection{Интегральная предельная теорема Муавра-Лапласа и интегральная формула Муавра-Лапласа}
Если в схеме Бернулли число испытаний $n$ велико,
то для вероятности $P\{m_1 \leq \mu \leq m_2\}$ того,
что число успехов $\mu$ заключено в пределах от $m_1$ до $m_2$,
справедливо приближенное соотношение (интегральная формула Муавра-Лапласа)
\begin{gather*}
	P\{m_1 \leq \mu \leq m_2\} \approx \Phi(x_2) - \Phi(x_1), \\
	x_1 = \frac{m_1 - np}{\sqrt{npq}}, x_2 = \frac{m_2 - np}{\sqrt{npq}}, \\
	\Phi(x) = \int_{-\infty}^{x}\varphi(y)dy = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-y^2/2}dy
\end{gather*}

Функция $\Phi(x)$, фигурирующая в интегральной формуле Муавра-Лапласа,
носит название функции стандартного нормального, или гауссова, распределения.
В силу четности $\varphi(x)$ функция стандартного нормального распределения обладает свойством
$\Phi(-x) = 1 - \Phi(x)$. Поэтому для вычислений можно использовать интеграла Лапласа
$\Phi_0(x) = \int^x_0\varphi(y)dy$ только для положительных $x$.
Ясно, что $\Phi_0(x)$ является нечетной функцией,
т.е. $\Phi_0(-x) = -\Phi_0(x)$ и, кроме того, $\Phi_0(x) = \Phi_0(x) + 1/2$.
В терминах интеграла Лапласа интегральная формула Муавра-Лапласа имеет вид
\[P\{m_1 \leq \mu \leq m_2\} \approx \Phi_0(x_2) - \Phi_0(x_1)\]

\subsection{Применение приближенных формул Пуассона и Муавра-Лапласа}
\subsection{Теорема Бернулли и слабый закон простых чисел}
\subsection{Полиномиальная схема и полиномиальное распределение}
Если схема Бернулли интерпретируется как подбрасывание несимметричной монеты,
то полиномиальную схему можно трактовать как обобщение статистики Максвелла-Больцмана на тот случай,
когда вероятности попадания каждой частицы в различные ячейки неодинаковы.
Предположим, что опыт состоит из $n$ независимых одинаковых испытаний,
в каждом из которых может произойти однои только одно из $m$ несовместных событий $A_1, ..., A_m$,
причем событие $A_i$ наступает с вероятностью $p_i$.
Тогда вероятность $P(n_1, ..., n_m)$ того, что в $n$ испытаниях событие $A_1$ произойдет ровно $n_1$ раз,
событие $A_m$ произойдет ровно $n_m$ раз $(n_1 + ... + n_m = n)$, определяется выражением
\[P(n_1, ..., n_m) = \frac{n!}{n_1!...n_m!}p_1^{n_1}...p_m^{n_m}\]

\section{Тема 6. Случайные величины общего вида}
\subsection{Случайная величина как функция преобразования вероятностного пространнства}
Случайной величиной $\xi$ называется функция,
ставящая в соответствие каждому элементарному исходу $\omega$ число $\xi = \xi(\omega)$. \\
Для того чтобы такое определение было математически корректным,
необходимо добавить следующее требование:
для любого числа $x$ множество $\{\omega: \xi(\omega) < x\}$ элементарных исходов $\omega$,
для которых $\xi(\omega) < x$, является событием, или, иными словами,
принадлежит $\sigma$-алгебре $\mathcal{B}$
(это свойство носит название измеримости функции $\xi = \xi(\omega)$
относительно $\sigma$-алгебры $\mathcal{B}$). \\
Таким образом, с точки зрения функционального анализа случайная величина представляет собой не что иное,
как обычную числовую функцию, заданную на пространстве элементарных исходов $\Omega$
(и измеримую относительно $\sigma$-алгебры $\mathcal{B}$).
Специфика теории вероятностей проявляется в том, что на $\Omega$ задана также вероятность $P$.

\subsection{Однозначное отображение пространства элементарных исходов в множестве действительных чисел}
\subsection{Многозначное обратное отображение пространнства элементарных исходов}
\subsection{Отображение сигма-алгебры событий в борелевскую сигма-алгебру числовых множеств}
\subsection{Определение случайной величины как измеримой функции}
\subsection{Функция распределения}
Функцией распределения (вероятностей) случайной величины $\xi$ называется функция $F(x)$,
значение которой в точке $x$ равно вероятности события $\{\xi < x\}$,
т. е. события, состоящего из тех и только тех элементарных исходов $\omega$, для которых $\xi(\omega) < x$
\[F(x) = P\{\xi < x\}\]
Обычно говорят, что значение функции распределения в точке $x$
равно вероятности случайной величине $\xi$ принять значение, меньшее $x$.

\subsection{Свойства функции распределения}
\begin{enumerate}
	\item $0 \leq F(x) \leq 1$
	\item $F(x_1) \leq F(x_2), x_1 < x_2$
	\item $F(-\infty) = 0, F(\infty) = 1$
	\item $P\{x_1 \leq \xi \leq x_2\} = F(x_2) - F(x_1)$
	\item $F(x) = F(x - 0)$ ($F(x)$ --- непрерывная слева функция)
\end{enumerate}

\subsection{Распределение вероятностей}

\section{Тема 7. Дискретные случайные величины}
\subsection{Дискретная случайная величина}
Дискретной называется случайная величина, которая каждому элементарному исходу $\omega$
ставит в соответствие одно из конечного (или в общем случае счетного) набора чисел
$X_1, X_2, ..., X_n$ ($X_1, X_2, ..., X_n, ...$.
Дискретную случайную величину удобно характеризовать рядом распределения.

\subsection{Распределение вероятностей и ряд распределения}
Рядом распределения (вероятностей) дискретной случайной величины называется таблица,
состоящая из двух строк:
в верхней строке перечислены все возможные значения случайной величины,
а в нижней --- вероятности $p_i = P\{\xi = X_i\}$ того, что случайная величина примет эти значения.
\begin{center}
	\begin{tabular}{| c | c | c | c | c | c | c |}
		\hline
		$\xi$ & $X_1$ & $X_2$ & $...$ & $X_i$ $...$ & $X_n$ \\
		\hline
		$P$   & $p_1$ & $p_2$ & $...$ & $p_i$ $...$ & $p_n$ \\
		\hline
	\end{tabular}
\end{center}

\subsection{Функция распределения дискретной случайной величины}
% Todo: draw graph
\subsection{Распределение Бернулли}
\subsection{Геометрическое распределение}
\subsection{Сдвинутое геометрическое распределение}
\subsection{Биноминальное распределение}
\subsection{Пуассоновское распределение}

\section{Тема 8. Непрерывные случайные величины}
\subsection{Непрерывная случайная величина}
Непрерывной называется случайная величина $\xi$,
функцию распределения которой $F(x)$ можно представить в виде
\[F(x) = \int^{x}_{-\infty}p(y)dy\]
Функция $p(x)$ называется плотностью распределения (вероятностей) случайной величины $\xi$.

\subsection{Плотность распредения и ее свойства}
\begin{enumerate}
	\item $p(x) \geq 0$
	\item $P\{x_1 \leq \xi \leq x_2\} = \int^{x_2}_{x_1}p(y)dy \because$ \\
	      $P\{x_1 \leq \xi \leq x_2\} = F(x_2) - F(x_1)$
	\item $\int^{\infty}_{-\infty}p(x)dx = 1 \because$ \\
	      $\{-\infty < \xi < \infty\}$ --- достоверное событие
	\item $P\{x \leq \xi \leq x + \Delta\} \approx p(x)\Delta$ \\
	      т.к. при малом $\Delta$ вероятность попадания на интервал $[x, x + \Delta)$
	      приближенно совпадает с площадью прямоугольника со сторонами $\Delta$ и $p(x)$.
	\item $P\{\xi = x\} = 0$ ($\Delta = 0$)
\end{enumerate}

\subsection{Равномерное непрерывное распределение}
\subsection{Экспоненциальное распределение}
\subsection{Распределение Вейбулла}
\subsection{Гамма-распределение}
\subsection{Нормальное (гауссовское) распределение}
\subsection{Стандартоное нормальное распределение}

\end{document}
